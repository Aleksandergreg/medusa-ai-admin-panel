# Promptfoo configuration for evaluating the Medusa Assistant HTTP endpoint
# Docs: https://www.promptfoo.dev/docs/configuration/ (no network needed to use this locally)

description: Evaluate my external AI assistant (Medusa Assistant API)

# The assistant endpoint accepts JSON with { prompt, wantsChart?, chartType?, chartTitle? }
# It returns JSON with { answer, chart, data, history }.

inputVars:
  - prompt
  - wantsChart
  - chartType
  - chartTitle

providers:
  # HTTP provider calling the backend assistant route. Requires a running backend at localhost:9000
  - id: http
    label: Medusa Assistant (local HTTP)
    config:
      url: http://localhost:9000/admin/assistant
      method: POST
      headers:
        Content-Type: application/json
        # Provide your Admin API key (sk_...) via environment variable when running promptfoo
        Authorization: "Basic {{env.MEDUSA_ADMIN_API_KEY}}"
      # Submit a JSON body with templated values
      body:
        prompt: "{{prompt}}"
        wantsChart: {{wantsChart | default(false)}}
        chartType: "{{chartType | default('bar')}}"
        chartTitle: "{{chartTitle | default('')}}"
      # Extract only the natural-language answer for scoring
      responsePath: answer

# Reference external dataset with prompts and assertions
datasets:
  - promptfoo/datasets/prompts.yaml

# Default, lightweight checks applied across tests unless overridden per-item
defaultTest:
  assert:
    - type: javascript
      # Ensure non-empty string output; tolerates full JSON responses
      value: "(((output && output.answer) ? String(output.answer) : (typeof output === 'string' ? output : '')).trim().length > 0)"
